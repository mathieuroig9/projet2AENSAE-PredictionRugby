{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 14 Rugby ?\n",
    "\n",
    "par Benjamin Cerf, Tristan Delhaye & Mathieu Roig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "à rédiger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sommaire\"></a>\n",
    "### Sommaire\n",
    "- [Introduction](#intro)\n",
    "  - [Sommaire](#sommaire)\n",
    "  - [Installation](#installation)\n",
    "- [Web-Scraping](#scraping)\n",
    "- [Nettoyage des données](#clean)\n",
    "- [Visualisation](#visual)\n",
    "- [Analyse](#analyse)\n",
    "- [Modèle prédictif](#predict)\n",
    "- [Conclusion](#conclu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"installation\"></a>\n",
    "### Installation\n",
    "\n",
    "à rédiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages:\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#lxml\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lxml\"])\n",
    "\n",
    "# ajouter pour partie predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scraping\"></a>\n",
    "# Web-Scraping\n",
    "\n",
    "Nous récupérons les données sur le championnat de France de rugby à XV de 2016 à aujourd'hui. Chaque saison a sa propre page wikipédia. Les différentes fonctions data dans scrapData.py récupèrent les tableaux de présentation générale, du classement et de son évolution, les résultats détaillés par match, et aussi la forme des équipes en fonction des jours de match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2016-2017', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2017-2018', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2018-2019', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2019-2020', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2020-2021', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2021-2022', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2022-2023', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2023-2024', 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_2024-2025']\n"
     ]
    }
   ],
   "source": [
    "urls = [f\"https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_{year}-{year+1}\"\n",
    "    for year in range(2016, 2025)]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.12/site-packages (5.3.0)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath('./scripts'))\n",
    "from scrapData import data2325, data2223, data2122, data2021, data1920, data1619\n",
    "\n",
    "tab1617 = data1619(urls[0])\n",
    "tab1718 = data1619(urls[1])\n",
    "tab1819 = data1619(urls[2])\n",
    "tab1920 = data1920(urls[3])\n",
    "tab2021 = data2021(urls[4])\n",
    "tab2122 = data2122(urls[5])\n",
    "tab2223 = data2223(urls[6])\n",
    "tab2324 = data2325(urls[7])\n",
    "tab2425 = data2325(urls[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clean\"></a>\n",
    "# Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanData import nettoyage\n",
    "\n",
    "nettoyage(*tab1617)\n",
    "nettoyage(*tab1718)\n",
    "nettoyage(*tab1819)\n",
    "nettoyage(*tab1920)\n",
    "nettoyage(*tab2021)\n",
    "nettoyage(*tab2122)\n",
    "nettoyage(*tab2223)\n",
    "nettoyage(*tab2324)\n",
    "nettoyage(*tab2425)\n",
    "\n",
    "# On va maintenant fusionner les tableaux on change le nom pour faciliter la boucle :\n",
    "tab1 = tab1617\n",
    "tab2 = tab1718\n",
    "tab3 = tab1819\n",
    "tab4 = tab1920\n",
    "tab5 = tab2021\n",
    "tab6 = tab2122\n",
    "tab7 = tab2223\n",
    "tab8 = tab2324\n",
    "tab9 = tab2425\n",
    "\n",
    "# On crée une fonction qui permet d'ajouter une colonne année à chaque tableau pour bien pouvoir les séparer par année si besoin après\n",
    "def ajout_an(df,i):\n",
    "   df[\"année\"] = 2016 + i\n",
    "   return df\n",
    "\n",
    "# On va faire maintenant une boucle pour concaténer les tableaux entre eux :\n",
    "tableauglobal = [pd.DataFrame() for _ in range(5)]\n",
    "# On remarquera que l'on ne prend pas le tableau résusltat global car les équipes du championnat changent chaque année donc ce n'est pas possible de le concaténer\n",
    "\n",
    "for j in range(1, 10):\n",
    "    for i in range(5):\n",
    "        if i == 2:\n",
    "            pass  # on ne récupère pas le tableau résultat\n",
    "        else:\n",
    "         tableauglobal[i] = pd.concat([tableauglobal[i], ajout_an(eval(f\"tab{j}\")[i], j - 1)], ignore_index=True)\n",
    "\n",
    "tab_presentation_global = tableauglobal[0]\n",
    "tab_classement_global = tableauglobal[1]\n",
    "tab_evolution_classement_global = tableauglobal[3]\n",
    "tab_forme_global = tableauglobal[4]\n",
    "tab_presentation_global['Budget en M€'] = pd.to_numeric(tab_presentation_global['Budget en M€'], errors='coerce')\n",
    "tab_presentation_global['Classement précédent'] = pd.to_numeric(tab_presentation_global['Classement précédent'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixer les données nettoyées dans SSPcloud ?\n",
    "\n",
    "#import s3fs\n",
    "#MY_BUCKET ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visual\"></a>\n",
    "# Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analyse\"></a>\n",
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "# Modèle prédictif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclu\"></a>\n",
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
