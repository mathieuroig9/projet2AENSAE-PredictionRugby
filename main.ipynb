{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Python - TOP14 Rugby\n",
    "\n",
    "Mathieu Roig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "Le projet est structuré de manière à guider l'utilisateur à travers les différentes étapes de l'analyse, de la collecte des données aux résultats. La section [Données](#données) détaille le processus de [Web-Scraping](#scraping), ainsi que les étapes de [Nettoyage](#nettoyage) et de [Regroupement](#regroupement) des données. Il y'aura ensuite une étape de [Visualisation](#visual) des données et leur [Analyse](#analyse). La dernière partie concerne les [Modèles prédictifs](#predict) avec d'abord la prédiction d'un champion une fois la saison régulière terminée puis dans un second temps la prédiction de matchs pour une saison vierge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sommaire\"></a>\n",
    "### Sommaire\n",
    "- [Données](#données)\n",
    "  - [Web-Scraping](#scraping)\n",
    "  - [Nettoyage](#nettoyage)\n",
    "  - [Uniformisation](#uniformisation)\n",
    "  - [Calendrier](#travail-sur-calendrier)\n",
    "  - [Regroupement](#regroupement)\n",
    "- [Statistiques Descriptives](#stats)\n",
    "  - [Visualisation](#visual)\n",
    "  - [Suivi des performances](#suivi-des-performances)\n",
    "- [Modèle prédictif](#predict)\n",
    "  - [Prédiction du champion](#classement)\n",
    "    - [Regression Logistique](#regression-logistique)\n",
    "    - [Random Forest](#random-forest)\n",
    "    - [XGBoost](#xgboost)\n",
    "  - [Prédiction par Elo](#prédiction-par-elo)\n",
    "    - [Test sur la saison 24/25](#test-sur-la-saison-2425)\n",
    "    - [Saison 25/26](#prédiction-sur-2526)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"installation\"></a>\n",
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages:\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#lxml\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lxml\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"données\"></a>\n",
    "# Données\n",
    "\n",
    "<a id=\"scraping\"></a>\n",
    "### Web-Scraping\n",
    "\n",
    "Je récupère sur Wikipédia les données sur le championnat de France de rugby à XV de 2016 à aujourd'hui. Chaque saison a sa propre page wikipédia dédiée et la présentation des résultats peut légèrement différer en fonction de l'année."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f\"https://fr.wikipedia.org/wiki/Championnat_de_France_de_rugby_%C3%A0_XV_{year}-{year+1}\"\n",
    "    for year in range(2005, 2025)]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons donc plusieurs versions d'une même fonction data dans scrapData.py qui récupère les tableaux de présentation générale, du classement, de son évolution, les scores par match, et aussi la forme des équipes (série de victoires ou de défautes) en fonction des différentes semaines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('./scripts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les fonctions dataXXXX posent souvent problème par impossibilité d'accès à wikipedia, en cas d'erreur \"list index out of range\" (qui signifie que l'accès à la table a été interdit par le site) elles sont disponibles dans le dossier dataBRUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scrapData import data2425,data2324, data2223, data2122, data2021, data1920, data1619, data1516x1314, data1415x1213, data1112, data1011, data0910, data0709, data0607, data0506 \n",
    "\n",
    "# tab0506 = data0506(urls[0])\n",
    "# time.sleep(2)\n",
    "# tab0607 = data0607(urls[1])\n",
    "# time.sleep(2)\n",
    "# tab0708 = data0709(urls[2])\n",
    "# time.sleep(2)\n",
    "# tab0809 = data0709(urls[3])\n",
    "# time.sleep(2)\n",
    "# tab0910 = data0910(urls[4])\n",
    "# time.sleep(2)\n",
    "# tab1011 = data1011(urls[5])\n",
    "# time.sleep(2)\n",
    "# tab1112 = data1112(urls[6])\n",
    "# time.sleep(2)\n",
    "# tab1213 = data1415x1213(urls[7])\n",
    "# time.sleep(2)\n",
    "# tab1314 = data1516x1314(urls[8])\n",
    "# time.sleep(2)\n",
    "# tab1415 = data1415x1213(urls[9])\n",
    "# time.sleep(2)\n",
    "# tab1516 = data1516x1314(urls[10])\n",
    "# time.sleep(2)\n",
    "# tab1617 = data1619(urls[11])\n",
    "# time.sleep(2)\n",
    "# tab1718 = data1619(urls[12])\n",
    "# time.sleep(2)\n",
    "# tab1819 = data1619(urls[13])\n",
    "# time.sleep(2)\n",
    "# tab1920 = data1920(urls[14])\n",
    "# time.sleep(2)\n",
    "# tab2021 = data2021(urls[15])\n",
    "# time.sleep(2)\n",
    "# tab2122 = data2122(urls[16])\n",
    "# time.sleep(2)\n",
    "# tab2223 = data2223(urls[17])\n",
    "# time.sleep(2)\n",
    "# tab2324 = data2324(urls[18])\n",
    "# time.sleep(2)\n",
    "# tab2425 = data2425(urls[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab0506=['','']\n",
    "tab0506[0] = pd.read_csv(\"dataBRUT/0506/cla0506.csv\")\n",
    "tab0506[1] = pd.read_csv(\"dataBRUT/0506/res0506.csv\")\n",
    "\n",
    "tab0607 = ['', '']\n",
    "tab0607[0] = pd.read_csv(\"dataBRUT/0607/cla0607.csv\")\n",
    "tab0607[1] = pd.read_csv(\"dataBRUT/0607/res0607.csv\")\n",
    "\n",
    "tab0708 = ['', '']\n",
    "tab0708[0] = pd.read_csv(\"dataBRUT/0708/cla0708.csv\")\n",
    "tab0708[1] = pd.read_csv(\"dataBRUT/0708/res0708.csv\")\n",
    "\n",
    "tab0809 = ['', '']\n",
    "tab0809[0] = pd.read_csv(\"dataBRUT/0809/cla0809.csv\")\n",
    "tab0809[1] = pd.read_csv(\"dataBRUT/0809/res0809.csv\")\n",
    "\n",
    "tab0910 = ['', '','']\n",
    "tab0910[0] = pd.read_csv(\"dataBRUT/0910/pre0910.csv\")\n",
    "tab0910[1] = pd.read_csv(\"dataBRUT/0910/cla0910.csv\")\n",
    "tab0910[2] = pd.read_csv(\"dataBRUT/0910/res0910.csv\")\n",
    "\n",
    "tab1011 = ['', '','','']\n",
    "tab1011[0] = pd.read_csv(\"dataBRUT/1011/pre1011.csv\")\n",
    "tab1011[1] = pd.read_csv(\"dataBRUT/1011/cla1011.csv\")\n",
    "tab1011[2] = pd.read_csv(\"dataBRUT/1011/res1011.csv\")\n",
    "tab1011[3] = pd.read_csv(\"dataBRUT/1011/evo1011.csv\")\n",
    "\n",
    "tab1112 = ['', '', '', '']\n",
    "tab1112[0] = pd.read_csv(\"dataBRUT/1112/pre1112.csv\")\n",
    "tab1112[1] = pd.read_csv(\"dataBRUT/1112/cla1112.csv\")\n",
    "tab1112[2] = pd.read_csv(\"dataBRUT/1112/res1112.csv\")\n",
    "tab1112[3] = pd.read_csv(\"dataBRUT/1112/evo1112.csv\")\n",
    "\n",
    "tab1213 = ['', '', '', '']\n",
    "tab1213[0] = pd.read_csv(\"dataBRUT/1213/pre1213.csv\")\n",
    "tab1213[1] = pd.read_csv(\"dataBRUT/1213/cla1213.csv\")\n",
    "tab1213[2] = pd.read_csv(\"dataBRUT/1213/res1213.csv\")\n",
    "tab1213[3] = pd.read_csv(\"dataBRUT/1213/evo1213.csv\")\n",
    "\n",
    "tab1314 = ['', '', '', '']\n",
    "tab1314[0] = pd.read_csv(\"dataBRUT/1314/pre1314.csv\")\n",
    "tab1314[1] = pd.read_csv(\"dataBRUT/1314/cla1314.csv\")\n",
    "tab1314[2] = pd.read_csv(\"dataBRUT/1314/res1314.csv\")\n",
    "tab1314[3] = pd.read_csv(\"dataBRUT/1314/evo1314.csv\")\n",
    "\n",
    "tab1415 = ['', '', '', '']\n",
    "tab1415[0] = pd.read_csv(\"dataBRUT/1415/pre1415.csv\")\n",
    "tab1415[1] = pd.read_csv(\"dataBRUT/1415/cla1415.csv\")\n",
    "tab1415[2] = pd.read_csv(\"dataBRUT/1415/res1415.csv\")\n",
    "tab1415[3] = pd.read_csv(\"dataBRUT/1415/evo1415.csv\")\n",
    "\n",
    "tab1516 = ['', '', '', '']\n",
    "tab1516[0] = pd.read_csv(\"dataBRUT/1516/pre1516.csv\")\n",
    "tab1516[1] = pd.read_csv(\"dataBRUT/1516/cla1516.csv\")\n",
    "tab1516[2] = pd.read_csv(\"dataBRUT/1516/res1516.csv\")\n",
    "tab1516[3] = pd.read_csv(\"dataBRUT/1516/evo1516.csv\")\n",
    "\n",
    "tab1617 = ['', '', '', '','']\n",
    "tab1617[0] = pd.read_csv(\"dataBRUT/1617/pre1617.csv\")\n",
    "tab1617[1] = pd.read_csv(\"dataBRUT/1617/cla1617.csv\")\n",
    "tab1617[2] = pd.read_csv(\"dataBRUT/1617/res1617.csv\")\n",
    "tab1617[3] = pd.read_csv(\"dataBRUT/1617/evo1617.csv\")\n",
    "tab1617[4] = pd.read_csv(\"dataBRUT/1617/for1617.csv\")\n",
    "\n",
    "tab1718 = ['', '', '', '', '']\n",
    "tab1718[0] = pd.read_csv(\"dataBRUT/1718/pre1718.csv\")\n",
    "tab1718[1] = pd.read_csv(\"dataBRUT/1718/cla1718.csv\")\n",
    "tab1718[2] = pd.read_csv(\"dataBRUT/1718/res1718.csv\")\n",
    "tab1718[3] = pd.read_csv(\"dataBRUT/1718/evo1718.csv\")\n",
    "tab1718[4] = pd.read_csv(\"dataBRUT/1718/for1718.csv\")\n",
    "\n",
    "tab1819 = ['', '', '', '', '']\n",
    "tab1819[0] = pd.read_csv(\"dataBRUT/1819/pre1819.csv\")\n",
    "tab1819[1] = pd.read_csv(\"dataBRUT/1819/cla1819.csv\")\n",
    "tab1819[2] = pd.read_csv(\"dataBRUT/1819/res1819.csv\")\n",
    "tab1819[3] = pd.read_csv(\"dataBRUT/1819/evo1819.csv\")\n",
    "tab1819[4] = pd.read_csv(\"dataBRUT/1819/for1819.csv\")\n",
    "\n",
    "tab1920 = ['', '', '', '', '']\n",
    "tab1920[0] = pd.read_csv(\"dataBRUT/1920/pre1920.csv\")\n",
    "tab1920[1] = pd.read_csv(\"dataBRUT/1920/cla1920.csv\")\n",
    "tab1920[2] = pd.read_csv(\"dataBRUT/1920/res1920.csv\")\n",
    "tab1920[3] = pd.read_csv(\"dataBRUT/1920/evo1920.csv\")\n",
    "tab1920[4] = pd.read_csv(\"dataBRUT/1920/for1920.csv\")\n",
    "\n",
    "tab2021 = ['', '', '', '', '']\n",
    "tab2021[0] = pd.read_csv(\"dataBRUT/2021/pre2021.csv\")\n",
    "tab2021[1] = pd.read_csv(\"dataBRUT/2021/cla2021.csv\")\n",
    "tab2021[2] = pd.read_csv(\"dataBRUT/2021/res2021.csv\")\n",
    "tab2021[3] = pd.read_csv(\"dataBRUT/2021/evo2021.csv\")\n",
    "tab2021[4] = pd.read_csv(\"dataBRUT/2021/for2021.csv\")\n",
    "\n",
    "tab2122 = ['', '', '', '', '']\n",
    "tab2122[0] = pd.read_csv(\"dataBRUT/2122/pre2122.csv\")\n",
    "tab2122[1] = pd.read_csv(\"dataBRUT/2122/cla2122.csv\")\n",
    "tab2122[2] = pd.read_csv(\"dataBRUT/2122/res2122.csv\")\n",
    "tab2122[3] = pd.read_csv(\"dataBRUT/2122/evo2122.csv\")\n",
    "tab2122[4] = pd.read_csv(\"dataBRUT/2122/for2122.csv\")\n",
    "\n",
    "tab2223 = ['', '', '', '', '']\n",
    "tab2223[0] = pd.read_csv(\"dataBRUT/2223/pre2223.csv\")\n",
    "tab2223[1] = pd.read_csv(\"dataBRUT/2223/cla2223.csv\")\n",
    "tab2223[2] = pd.read_csv(\"dataBRUT/2223/res2223.csv\")\n",
    "tab2223[3] = pd.read_csv(\"dataBRUT/2223/evo2223.csv\")\n",
    "tab2223[4] = pd.read_csv(\"dataBRUT/2223/for2223.csv\")\n",
    "\n",
    "tab2324 = ['', '', '', '', '']\n",
    "tab2324[0] = pd.read_csv(\"dataBRUT/2324/pre2324.csv\")\n",
    "tab2324[1] = pd.read_csv(\"dataBRUT/2324/cla2324.csv\")\n",
    "tab2324[2] = pd.read_csv(\"dataBRUT/2324/res2324.csv\")\n",
    "tab2324[3] = pd.read_csv(\"dataBRUT/2324/evo2324.csv\")\n",
    "tab2324[4] = pd.read_csv(\"dataBRUT/2324/for2324.csv\")\n",
    "\n",
    "tab2425 = ['', '', '', '', '']\n",
    "tab2425[0] = pd.read_csv(\"dataBRUT/2425/pre2425.csv\")\n",
    "tab2425[1] = pd.read_csv(\"dataBRUT/2425/cla2425.csv\")\n",
    "tab2425[2] = pd.read_csv(\"dataBRUT/2425/res2425.csv\")\n",
    "tab2425[3] = pd.read_csv(\"dataBRUT/2425/evo2425.csv\")\n",
    "tab2425[4] = pd.read_csv(\"dataBRUT/2425/for2425.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nettoyage\"></a>\n",
    "### Nettoyage\n",
    "\n",
    "La fonction nettoyage de cleanData.py uniformise les données du scraping. Les noms des équipes sont nettoyés, on se débarrasse des notes, et les classements sont tous mis sous forme numérique (ex: 1er -> 1, 2ème -> 2...). Les valeurs manquantes sont aussi remplacées par un tiret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanData import nettoyage\n",
    "nettoyage(None, tab0506[0], tab0506[1], None, None, do_pre=False, do_evo=False, do_for=False)\n",
    "nettoyage(None, tab0607[0], tab0607[1], None, None, do_pre=False, do_evo=False, do_for=False)\n",
    "nettoyage(None, tab0708[0], tab0708[1], None, None, do_pre=False, do_evo=False, do_for=False)\n",
    "nettoyage(None, tab0809[0], tab0809[1], None, None, do_pre=False, do_evo=False, do_for=False)\n",
    "nettoyage(tab0910[0], tab0910[1], tab0910[2],None, None, do_evo=False, do_for=False)\n",
    "nettoyage(tab1011[0], tab1011[1], tab1011[2],tab1011[3], None, do_for=False)\n",
    "nettoyage(tab1112[0], tab1112[1], tab1112[2],tab1112[3], None, do_for=False)\n",
    "nettoyage(tab1213[0], tab1213[1], tab1213[2],tab1213[3], None, do_for=False)\n",
    "nettoyage(tab1314[0], tab1314[1], tab1314[2],tab1314[3], None, do_for=False)\n",
    "nettoyage(tab1415[0], tab1415[1], tab1415[2],tab1415[3], None, do_for=False)\n",
    "nettoyage(tab1516[0], tab1516[1], tab1516[2],tab1516[3], None, do_for=False)\n",
    "nettoyage(*tab1617)\n",
    "nettoyage(*tab1718)\n",
    "nettoyage(*tab1819)\n",
    "nettoyage(*tab1920)\n",
    "nettoyage(*tab2021)\n",
    "nettoyage(*tab2122)\n",
    "nettoyage(*tab2223)\n",
    "nettoyage(*tab2324)\n",
    "nettoyage(*tab2425)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"uniformisation\"></a>\n",
    "\n",
    "### Uniformisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut pour chaque année les tableaux : présentation, classement, résultats, évolution, forme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab0506 = [None, tab0506[0], tab0506[1], None, None]\n",
    "tab0607 = [None, tab0607[0], tab0607[1], None, None]\n",
    "tab0708 = [None, tab0708[0], tab0708[1], None, None]\n",
    "tab0809 = [None, tab0809[0], tab0809[1], None, None]\n",
    "tab0910 = [tab0910[0], tab0910[1], tab0910[2], None, None]\n",
    "tab1011 = [tab1011[0], tab1011[1], tab1011[2], tab1011[3], None]\n",
    "tab1112 = [tab1112[0], tab1112[1], tab1112[2], tab1112[3], None]\n",
    "tab1213 = [tab1213[0], tab1213[1], tab1213[2], tab1213[3], None]\n",
    "tab1314 = [tab1314[0], tab1314[1], tab1314[2], tab1314[3], None]\n",
    "tab1415 = [tab1415[0], tab1415[1], tab1415[2], tab1415[3], None]\n",
    "tab1516 = [tab1516[0], tab1516[1], tab1516[2], tab1516[3], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va maintenant fusionner les tableaux, on change le nom pour faciliter la boucle :\n",
    "tab1 = tab0506\n",
    "tab2 = tab0607\n",
    "tab3 = tab0708\n",
    "tab4 = tab0809\n",
    "tab5 = tab0910\n",
    "tab6 = tab1011\n",
    "tab7 = tab1112\n",
    "tab8 = tab1213\n",
    "tab9 = tab1314\n",
    "tab10 = tab1415\n",
    "tab11 = tab1516\n",
    "tab12 = tab1617\n",
    "tab13 = tab1718\n",
    "tab14 = tab1819\n",
    "tab15 = tab1920\n",
    "tab16 = tab2021\n",
    "tab17 = tab2122\n",
    "tab18 = tab2223\n",
    "tab19 = tab2324\n",
    "tab20 = tab2425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes = [\"Club\",\"Dernière montée\",\"Budget en M€\",\"Classement précédent\",\"Entraîneur en chef\",\"Stade\",\"Capacité\"]\n",
    "def init_df():\n",
    "    return pd.DataFrame([[np.nan]*len(colonnes)], columns=colonnes)\n",
    "\n",
    "for tab in (tab1, tab2, tab3, tab4):\n",
    "    if tab[0] is None:\n",
    "        tab[0] = init_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"uniformisation\"></a>\n",
    "\n",
    "### Travail sur calendrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problème se pose pour les tableaux évolution et forme qui n'apparaissent plus respectivement à partir de 2011 et 2016, il faut donc les reconstruire à partir de résultats mais ce dernier ne donne que les scores des matchs sans l'ordre des journées, il faut donc rajouter ces informations pour avoir des informations pour chaque journées (classement à la fin de la journée pour évolution, victoire/nul/défaite pour forme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendrierData import make_calBIN_from_mapped, build_points_diff_table, build_rank_table, reshape_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un gros travail de mapping doit être fait pour uniformiser le nom d'équipe comme : USAP, USA Perpignan, Perpignan ; ou même encore plus simple les cas : Stade Toulousain et Stade toulousain qui ne sont pas reconnus pareil ce qui va poser des problèmes pour mener des études statistiques dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Montferrand\": \"ASM Clermont\",\n",
    "    'Paris' : 'Stade français Paris',\n",
    "    'Stade français': 'Stade français Paris',\n",
    "    'Clermont': 'ASM Clermont',\n",
    "    'La Rochelle': 'Stade rochelais',\n",
    "    'Toulouse': 'Stade toulousain',\n",
    "    'Stade toulousain T': 'Stade toulousain',\n",
    "    'Bayonne': 'Aviron bayonnais',\n",
    "    'Brive': 'CA Brive',\n",
    "    'Montpellier': 'Montpellier HR',\n",
    "    'Montpellier RC': 'Montpellier HR',\n",
    "    'Toulon': 'RC Toulon',\n",
    "    'Castres': 'Castres olympique',\n",
    "    'Pau': 'Section paloise',\n",
    "    'Agen': 'SU Agen',\n",
    "    'Grenoble': 'FC Grenoble',\n",
    "    'Oyonnax': 'US Oyonnax',\n",
    "    'Perpignan': 'USA Perpignan',\n",
    "    'Bordeaux-Bègles': 'Union Bordeaux Bègles',\n",
    "    'Bordeaux Bègles' : 'Union Bordeaux Bègles',\n",
    "    'Lyon' : 'Lyon OU',\n",
    "    'ASM Clermont Auvergne': 'ASM Clermont',\n",
    "    'Biarritz O.': 'Biarritz Olympique',\n",
    "    'Biarritz olympique': 'Biarritz Olympique',\n",
    "    'Bourgoin-Jallieu': 'CS Bourgoin-Jallieu',\n",
    "    'Castres O.': 'Castres olympique',\n",
    "    'Montpellier RC': 'Montpellier HR',\n",
    "    'Oyonnax Rugby': 'US Oyonnax',\n",
    "    'Racing Métro 92': 'Racing 92',\n",
    "    'Montauban TGXV': 'US Montauban',\n",
    "    'Stade montois': 'Stade Montois',\n",
    "    \"Auch\": \"FC Auch Gers\",\n",
    "    \"FC Auch\": \"FC Auch Gers\",\n",
    "    'Albi': 'SC Albi',\n",
    "    'Biarritz': 'Biarritz Olympique',\n",
    "    'Bourgoin': 'CS Bourgoin-Jallieu',\n",
    "    'Dax': 'US Dax',\n",
    "    'Mont de Marsan': 'Stade Montois',\n",
    "    'Montauban': 'US Montauban',\n",
    "    'Narbonne': 'RC Narbonne',\n",
    "    'Stade Français': 'Stade français Paris',\n",
    "    'Stade Toulousain': 'Stade toulousain',\n",
    "    'USAP': 'USA Perpignan',\n",
    "    \"Racing Metro 92\": \"Racing 92\",\n",
    "    \"LOU\" : \"Lyon OU\"}\n",
    "\n",
    "abbr_mapping = {\n",
    "    \"AGE\": \"SU Agen\",\n",
    "    \"BAY\": \"Aviron bayonnais\",\n",
    "    \"BIA\": \"Biarritz Olympique\",\n",
    "    \"BOU\": \"CS Bourgoin-Jallieu\",\n",
    "    \"BRI\": \"CA Brive\",\n",
    "    \"CAS\": \"Castres olympique\",\n",
    "    \"CLE\": \"ASM Clermont\",\n",
    "    \"MPL\": \"Montpellier HR\",\n",
    "    \"NAR\": \"RC Narbonne\",\n",
    "    \"PAU\": \"Section paloise\",\n",
    "    \"PER\": \"USA Perpignan\",\n",
    "    \"STF\": \"Stade français Paris\",\n",
    "    \"TLN\": \"RC Toulon\",\n",
    "    \"TLS\": \"Stade toulousain\",\n",
    "\n",
    "    \"ALB\": \"SC Albi\",\n",
    "    \"AUC\": \"FC Auch Gers\",\n",
    "    \"DAX\": \"US Dax\",\n",
    "    \"MDM\": \"Stade Montois\",\n",
    "    \"MTB\": \"US Montauban\",  \n",
    "\n",
    "    \"UBB\": \"Union Bordeaux Bègles\",\n",
    "    \"CAB\": \"CA Brive\",\n",
    "    \"MHR\": \"Montpellier HR\",        # alias qui pointe vers le libellé exact de res\n",
    "    \"SFR\": \"Stade français Paris\",\n",
    "    \"TOU\": \"Stade toulousain\",\n",
    "    \"GRE\": \"FC Grenoble\",\n",
    "    \"LOU\": \"Lyon OU\",\n",
    "    \"RAC\": \"Racing 92\",\n",
    "    \"ROC\": \"Stade rochelais\",\n",
    "    \"OYO\": \"US Oyonnax\",\n",
    "    \"VAN\": \"RC Vannes\",\n",
    "\n",
    "    \"BOB\": \"Union Bordeaux Bègles\",   \n",
    "    \"MRC\": \"Montpellier HR\",\n",
    "    \"RCT\": \"RC Toulon\",\n",
    "    \"SCA\": \"SC Albi\",\n",
    "    \"SUA\": \"SU Agen\",\n",
    "    \"USM\": \"US Montauban\",\n",
    "    \"USO\": \"US Oyonnax\",\n",
    "    \n",
    "    \"BOR\": \"Union Bordeaux Bègles\",\n",
    "    \"LAR\": \"Stade rochelais\",\n",
    "    \"LYO\": \"Lyon OU\",\n",
    "    \"MON\": \"Montpellier HR\",\n",
    "}\n",
    "\n",
    "cal_lower_mapping = {\n",
    "    \"agen\": \"su agen\",\n",
    "    \"albi\": \"sc albi\",\n",
    "    \"auch\": \"fc auch gers\",\n",
    "    \"bayonne\": \"aviron bayonnais\",\n",
    "    \"biarritz\": \"biarritz olympique\",\n",
    "    \"bourgoin\": \"cs bourgoin-jallieu\",\n",
    "    \"brive\": \"ca brive\",\n",
    "    \"castres\": \"castres olympique\",\n",
    "    \"clermont\": \"asm clermont\",\n",
    "    \"dax\": \"us dax\",\n",
    "    \"mont de marsan\": \"stade montois\",\n",
    "    \"montauban\": \"us montauban\",\n",
    "    \"montferrand\": \"asm clermont\",\n",
    "    \"montpellier\": \"montpellier hr\",\n",
    "    \"narbonne\": \"rc narbonne\",\n",
    "    \"pau\": \"section paloise\",\n",
    "    \"stade français\": \"stade français paris\",\n",
    "    \"stade toulousain\": \"stade toulousain\",\n",
    "    \"toulon\": \"rc toulon\",\n",
    "    \"usap\": \"usa perpignan\",\n",
    "    \"la rochelle\": \"stade rochelais\",\n",
    "    \"racing metro 92\":\"racing 92\",\n",
    "    \"racing métro 92\":\"racing 92\",\n",
    "    \"lou\": \"lyon ou\",\n",
    "    \"grenoble\": \"fc grenoble\",\n",
    "    \"oyonnax\": \"us oyonnax\",\n",
    "}\n",
    "\n",
    "cal_upper_mapping = {\n",
    "    \"AGEN\": \"SU AGEN\",\n",
    "    \"ALBI\": \"SC ALBI\",\n",
    "    \"AUCH\": \"FC AUCH GERS\",\n",
    "    \"BAYONNE\": \"AVIRON BAYONNAIS\",\n",
    "    \"BIARRITZ\": \"BIARRITZ OLYMPIQUE\",\n",
    "    \"BOURGOIN\": \"CS BOURGOIN-JALLIEU\",\n",
    "    \"BRIVE\": \"CA BRIVE\",\n",
    "    \"CASTRES\": \"CASTRES OLYMPIQUE\",\n",
    "    \"CLERMONT\": \"ASM CLERMONT\",\n",
    "    \"DAX\": \"US DAX\",\n",
    "    \"MONT DE MARSAN\": \"STADE MONTOIS\",\n",
    "    \"MONTAUBAN\": \"US MONTAUBAN\",\n",
    "    \"MONTFERRAND\" : \"ASM CLERMONT\",\n",
    "    \"MONTPELLIER\": \"MONTPELLIER HR\",\n",
    "    \"NARBONNE\": \"RC NARBONNE\",\n",
    "    \"PAU\": \"SECTION PALOISE\",\n",
    "    \"LA ROCHELLE\": \"STADE ROCHELAIS\",\n",
    "    \"STADE FRANÇAIS\": \"STADE FRANÇAIS PARIS\",\n",
    "    \"STADE TOULOUSAIN\": \"STADE TOULOUSAIN\",\n",
    "    \"TOULON\": \"RC TOULON\",\n",
    "    \"USAP\": \"USA PERPIGNAN\",\n",
    "    \"RACING METRO 92\":\"RACING 92\",\n",
    "    \"RACING MÉTRO 92\":\"RACING 92\",\n",
    "    \"LOU\": \"LYON OU\",\n",
    "    \"GRENOBLE\": \"FC GRENOBLE\",\n",
    "    \"OYONNAX\": \"US OYONNAX\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_res = {}\n",
    "\n",
    "for i in range(1, 12):  # de tab1 à tab11 inclus\n",
    "    df = globals()[f\"tab{i}\"][2].copy()\n",
    "    \n",
    "    # Remplacer abréviations (ligne 0, colonnes sauf la première)\n",
    "    df.iloc[0, 1:] = df.iloc[0, 1:].replace(abbr_mapping)\n",
    "    \n",
    "    # Remplacer noms domicile (première colonne sauf l’entête)\n",
    "    df.iloc[1:, 0] = df.iloc[1:, 0].replace(mapping)\n",
    "    \n",
    "    # Sauvegarder\n",
    "    normalized_res[f\"res{i:02d}\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saisons à traiter\n",
    "seasons = [\"0506\",\"0607\",\"0708\",\"0809\",\"0910\",\"1011\",\"1112\",\"1213\",\"1314\",\"1415\",\"1516\"]\n",
    "\n",
    "def map_team_name(cell: str):\n",
    "    if pd.isna(cell) or cell == \"\":\n",
    "        return cell\n",
    "    s = str(cell).strip()\n",
    "    if s.isupper():\n",
    "        # MAJUSCULE = la colonne joue à domicile\n",
    "        return cal_upper_mapping.get(s, s)\n",
    "    else:\n",
    "        # minuscules = la colonne joue à l'extérieur\n",
    "        return cal_lower_mapping.get(s, s)\n",
    "\n",
    "cal_norm = {}\n",
    "\n",
    "for season in seasons:\n",
    "    df = pd.read_csv(f\"dataLLM/{season}cal.csv\")\n",
    "\n",
    "    # 1) appliquer le mapping cellule par cellule sur les colonnes équipes\n",
    "    team_cols = df.columns[1:]\n",
    "    for col in team_cols:\n",
    "        df[col] = df[col].apply(map_team_name)\n",
    "\n",
    "    # 2) renommer la première colonne en \"Journées\"\n",
    "    df.rename(columns={df.columns[0]: \"Journées\"}, inplace=True)\n",
    "\n",
    "    # 3) renommer les en-têtes d'équipes avec col_to_resname\n",
    "    #    (on garde tel quel si la clé n'est pas dans le mapping)\n",
    "    header_map = {col: mapping.get(col, col) for col in team_cols}\n",
    "    df.rename(columns=header_map, inplace=True)\n",
    "\n",
    "    cal_norm[season] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calBINs = {}\n",
    "\n",
    "for i, year in enumerate(range(506, 1517, 101)):  # 0506, 0607, ..., 1516\n",
    "    year_str = str(year).zfill(4)      # \"0506\", \"0607\", ...\n",
    "    res_key = f\"res{str(i+1).zfill(2)}\"  # \"res01\", \"res02\", ...\n",
    "    \n",
    "    calBINs[year_str] = make_calBIN_from_mapped(\n",
    "        cal_norm[year_str],\n",
    "        normalized_res[res_key]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec calBIN on a complètement les matrices forme, il manque à les uniformiser dans le format des autres, i.e journées en colonnes et aussi à calculer les matrices evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = {}\n",
    "\n",
    "for year_str, calBIN in calBINs.items():\n",
    "    # trouver le bon res_key à partir de l’année\n",
    "    # ex: \"0506\" → \"res01\", \"0607\" → \"res02\", etc.\n",
    "    idx = list(calBINs.keys()).index(year_str) + 1\n",
    "    res_key = f\"res{str(idx).zfill(2)}\"\n",
    "    \n",
    "    points_diff = build_points_diff_table(calBIN, normalized_res[res_key])\n",
    "    ranks[year_str] = build_rank_table(points_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evos = {}\n",
    "fors = {}\n",
    "\n",
    "for year in ranks.keys():  # \"0506\", \"0607\", ..., \"1516\"\n",
    "    # Pour le classement (rank → evo)\n",
    "    evos[f\"evo{year}\"] = reshape_table(ranks[year])\n",
    "\n",
    "    # Pour les résultats (calBIN → for)\n",
    "    fors[f\"for{year}\"] = reshape_table(calBINs[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(506, 911, 101):  # 0506 -> 0910, par pas de 101\n",
    "    key = f\"evo{str(i).zfill(4)}\"  # génère \"evo0506\", etc.\n",
    "    tab_name = f\"tab{str(i).zfill(4)}\"  # génère \"tab0506\", etc.\n",
    "    globals()[tab_name][3] = evos[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(506, 1517, 101):  # 0506 -> 1516, par pas de 101\n",
    "    key = f\"for{str(i).zfill(4)}\"       # ex: \"for0506\"\n",
    "    tab_name = f\"tab{str(i).zfill(4)}\"  # ex: \"tab0506\"\n",
    "    globals()[tab_name][4] = fors[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"regroupement\"></a>\n",
    "### Regroupement\n",
    "\n",
    "On fusionne tous les tableaux pour travailler plus facilement avec par la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée une fonction qui permet d'ajouter une colonne année à chaque tableau pour bien pouvoir les séparer par année si besoin après\n",
    "def ajout_an(df,i):\n",
    "   df[\"année\"] = 2005 + i\n",
    "   return df\n",
    "\n",
    "# On va faire maintenant une boucle pour concaténer les tableaux entre eux :\n",
    "tableauglobal = [pd.DataFrame() for _ in range(5)]\n",
    "\n",
    "for j in range(1, 21):\n",
    "    for i in range(5):\n",
    "         tableauglobal[i] = pd.concat([tableauglobal[i], ajout_an(eval(f\"tab{j}\")[i], j - 1)], ignore_index=True)\n",
    "\n",
    "tab_presentation_global = tableauglobal[0]\n",
    "tab_classement_global = tableauglobal[1]\n",
    "tab_resultat_global = tableauglobal[2]\n",
    "tab_evolution_classement_global = tableauglobal[3]\n",
    "tab_forme_global = tableauglobal[4]\n",
    "# On convertit aussi ceraines données au format numérique\n",
    "tab_presentation_global['Budget en M€'] = pd.to_numeric(tab_presentation_global['Budget en M€'], errors='coerce')\n",
    "tab_presentation_global['Classement précédent'] = pd.to_numeric(tab_presentation_global['Classement précédent'], errors='coerce')\n",
    "#on enleve les journées de rattrapage inutiles\n",
    "tab_forme_global = tab_forme_global.iloc[:, :-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que le mapping a bien été fait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation = tab_presentation_global\n",
    "classement = tab_classement_global\n",
    "evolution = tab_evolution_classement_global\n",
    "forme = tab_forme_global\n",
    "resultat = tab_resultat_global\n",
    "resultat.rename(columns={resultat.columns[0]: \"Club\"}, inplace=True)\n",
    "resultat = resultat.fillna(\"-\")\n",
    "\n",
    "# On commence déjà par uniformiser le nom de la colonne 'Club':\n",
    "evolution.rename(columns={'Equipes/Journées': 'Club'}, inplace=True)\n",
    "forme.rename(columns={'Equipes/Journées': 'Club'}, inplace=True)\n",
    "\n",
    "# On a plus qu'à uniformiser les noms dans tout les tableaux\n",
    "presentation['Club'] = presentation['Club'].replace(mapping)\n",
    "classement['Club'] = classement['Club'].replace(mapping)\n",
    "forme['Club'] = forme['Club'].replace(mapping)\n",
    "evolution['Club'] = evolution['Club'].replace(mapping)\n",
    "\n",
    "#pour resultat c'est plus compliqué car toutes les 15 lignes on a un mapping différent du précédent\n",
    "resultat = resultat.rename(columns={0: \"Club\"})\n",
    "\n",
    "# Parcours des lignes 0, 15, 30, ...\n",
    "for i in range(0, len(resultat), 15):\n",
    "    if i < len(resultat):\n",
    "        resultat.iloc[i, 1:-1] = resultat.iloc[i, 1:-1].replace(abbr_mapping)\n",
    "\n",
    "resultat['Club'] = resultat['Club'].apply(\n",
    "    lambda x: mapping[x] if x in mapping and x != \"Clubs\" else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va ensuite sauvegarder tous les tableaux dans le dossier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# presentation.to_csv('data/presentation.csv',index=False)\n",
    "# classement.to_csv('data/classement.csv',index=False)\n",
    "# forme.to_csv('data/forme.csv',index=False)\n",
    "# evolution.to_csv('data/evolution.csv',index=False)\n",
    "# resultat.to_csv('data/resultat.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou les récupérer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation=pd.read_csv('data/presentation.csv')\n",
    "classement=pd.read_csv('data/classement.csv')\n",
    "forme=pd.read_csv('data/forme.csv')\n",
    "evolution=pd.read_csv('data/evolution.csv')\n",
    "resultat=pd.read_csv('data/resultat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stats\"></a>\n",
    "# Statistiques Descriptives\n",
    "\n",
    "<a id=\"visual\"></a>\n",
    "### Visualisation\n",
    "\n",
    "La fonction club de computeData permet d'obtenir les statistiques descriptives pour un club en particulier, pour chaque année qu'il passe dans le top 14: son budget en M€, son entraîneur, son rang, et le nombre de recontres jouées, dont les victoires et les défaites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from computeData import club\n",
    "\n",
    "toulouse=club(\"Stade toulousain\", presentation, classement)\n",
    "toulouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perpignan=club(\"USA Perpignan\", presentation, classement)\n",
    "perpignan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut visualiser l'évolution du budget des clubs au sein du championnat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "df_plot = presentation[presentation[\"Budget en M€\"].notna()]\n",
    "sns.boxplot(x=\"année\", y=\"Budget en M€\", data=df_plot, palette=\"YlOrBr\")\n",
    "\n",
    "plt.title(\"Distribution du Budget des Clubs de 2009 à 2024\")\n",
    "plt.xlabel(\"Année\")\n",
    "plt.ylabel(\"Budget en M€\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget2024 = presentation[presentation[\"année\"] == 2024]\n",
    "budget2024[[\"Club\", \"Budget en M€\"]].sort_values(by=\"Budget en M€\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visualise l'évolution du trio de tête :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "clubs_selectionnes = [\"Stade toulousain\",\"Stade rochelais\",\"RC Toulon\",\"Union Bordeaux Bègles\"]\n",
    "\n",
    "couleurs = {\"Stade toulousain\": \"red\",\"Stade rochelais\": \"gold\",\"RC Toulon\": \"black\",\"Union Bordeaux Bègles\": \"blue\"}\n",
    "\n",
    "\n",
    "# filtrer pour le top et uniquement ces clubs\n",
    "top_clubs = (\n",
    "    classement.sort_values(by=[\"année\", \"Rang\"])\n",
    "    .groupby(\"année\")\n",
    "    .head(14)\n",
    "    .query(\"Club in @clubs_selectionnes\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for club in top_clubs[\"Club\"].unique():\n",
    "    club_data = top_clubs[top_clubs[\"Club\"] == club]\n",
    "    plt.plot(club_data[\"année\"], club_data[\"Rang\"], marker=\"o\", label=club, color=couleurs[club], linewidth=2)\n",
    "    \n",
    "plt.gca().invert_yaxis()  # mettre 1 en haut\n",
    "plt.ylim(14.3, 0.7)\n",
    "\n",
    "plt.title(\"Évolution du classement des clubs sélectionnés (2005-2024)\")\n",
    "plt.xlabel(\"Saison\")\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.ylabel(\"Classement\")\n",
    "plt.legend(title=\"Club\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Suivi des performances\"></a>\n",
    "### Suivi des performances\n",
    "\n",
    "Continuons par analyser d'autres graphiques, en étudiant en particulier les tables évolution et forme :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from computeData import plot_club_evolution\n",
    "\n",
    "plot_club_evolution(\"Stade toulousain\", evolution, forme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_club_evolution(\"Union Bordeaux Bègles\", evolution, forme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_club_evolution(\"USA Perpignan\", evolution, forme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "# Modèle prédictif\n",
    "\n",
    "Après un aperçu des données à notre disposition, nous allons chercher à répondre à 2 questions : \n",
    "- peut-on prédire le champion de la saison, i.e à la fin des 26 journées, savoir qui remporte les phases finales ?\n",
    "- peut-on prédire une saison entière avant qu'elle ne commence, et comment évolue cette prédiction au fur et à mesure que les journées soient connues ?\n",
    "\n",
    "<a id=\"predictionChampion\"></a>\n",
    "### Prédiction du champion\n",
    "\n",
    "Tout d'abord affichons le champion des dernières années :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages:\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#lxml\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lxml\"])\n",
    "\n",
    "# pour partie predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "presentation=pd.read_csv('data/presentation.csv')\n",
    "classement=pd.read_csv('data/classement.csv')\n",
    "forme=pd.read_csv('data/forme.csv')\n",
    "evolution=pd.read_csv('data/evolution.csv')\n",
    "resultat=pd.read_csv('data/resultat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Données champions avec noms normalisés (conformes à ton mapping)\n",
    "data_enligne = [\n",
    "    {\"année\": 2005, \"champion\": \"Biarritz Olympique\"},\n",
    "    {\"année\": 2006, \"champion\": \"Stade français Paris\"},\n",
    "    {\"année\": 2007, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2008, \"champion\": \"USA Perpignan\"},\n",
    "    {\"année\": 2009, \"champion\": \"ASM Clermont\"},\n",
    "    {\"année\": 2010, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2011, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2012, \"champion\": \"Castres olympique\"},\n",
    "    {\"année\": 2013, \"champion\": \"RC Toulon\"},\n",
    "    {\"année\": 2014, \"champion\": \"Stade français Paris\"},\n",
    "    {\"année\": 2015, \"champion\": \"Racing 92\"},\n",
    "    {\"année\": 2016, \"champion\": \"ASM Clermont\"},\n",
    "    {\"année\": 2017, \"champion\": \"Castres olympique\"},\n",
    "    {\"année\": 2018, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2019, \"champion\": None},  # saison annulée\n",
    "    {\"année\": 2020, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2021, \"champion\": \"Montpellier HR\"},\n",
    "    {\"année\": 2022, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2023, \"champion\": \"Stade toulousain\"},\n",
    "    {\"année\": 2024, \"champion\": \"Stade toulousain\"},\n",
    "]\n",
    "\n",
    "# Vice-champions avec noms normalisés\n",
    "vice_champions = {\n",
    "    2005: \"Stade français Paris\",\n",
    "    2006: \"ASM Clermont\",\n",
    "    2007: \"ASM Clermont\",\n",
    "    2008: \"ASM Clermont\",\n",
    "    2009: \"USA Perpignan\",\n",
    "    2010: \"USA Perpignan\",\n",
    "    2011: \"Montpellier HR\",\n",
    "    2012: \"Stade toulousain\",\n",
    "    2013: \"Castres olympique\",\n",
    "    2014: \"Castres olympique\",\n",
    "    2015: \"ASM Clermont\",\n",
    "    2016: \"RC Toulon\",\n",
    "    2017: \"RC Toulon\",\n",
    "    2018: \"ASM Clermont\",\n",
    "    2019: None,  # annulée\n",
    "    2020: \"Stade rochelais\",\n",
    "    2021: \"Castres olympique\",\n",
    "    2022: \"Stade rochelais\",\n",
    "    2023: \"Stade rochelais\",\n",
    "    2024: \"Union Bordeaux Bègles\",\n",
    "}\n",
    "\n",
    "# Compléter le dataframe\n",
    "for row in data_enligne:\n",
    "    row[\"vice_champion\"] = vice_champions.get(row[\"année\"], None)\n",
    "\n",
    "df_champions = pd.DataFrame(data_enligne)\n",
    "df_champions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction du champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_cleandata import extract_features_top14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_features_top14(classement, evolution, forme, df_champions, resultats=resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"regressionlogistique\"></a>\n",
    "\n",
    "### Regression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_reg import fit_predict_logit, evaluate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, probs = fit_predict_logit(features, df_champions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = evaluate_results(results, probs)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"randomForest\"></a>\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_reg import run_random_forest_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_RF, year_table_RF, metrics_RF = run_random_forest_simple(\n",
    "    features, df_champions,\n",
    "    calibrate=False,         # commence SANS calibration\n",
    "    blend_prior=True,        # active le prior de rang\n",
    "    prior_kind=\"rank\",       # \"rank\" ou \"points\"\n",
    "    prior_temp=0.8,          # 0.6 ↔ 1.2 à tester\n",
    "    alpha=0.30               # poids du prior (0.2–0.5 à tester)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Mini-grid simple à tester ---\n",
    "configs = [\n",
    "    dict(name=\"base_like\",   n_estimators=1200, max_depth=10, max_features=\"sqrt\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"more_trees\",  n_estimators=2000, max_depth=10, max_features=\"sqrt\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"deeper\",      n_estimators=1200, max_depth=None, max_features=\"sqrt\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"log2_feats\",  n_estimators=1200, max_depth=10, max_features=\"log2\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"feat_60pc\",   n_estimators=1200, max_depth=10, max_features=0.6,   min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"leaf1\",       n_estimators=1200, max_depth=10, max_features=\"sqrt\", min_samples_leaf=1, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"no_weight\",   n_estimators=1200, max_depth=10, max_features=\"sqrt\", min_samples_leaf=2, class_weight=None,      criterion=\"gini\"),\n",
    "    dict(name=\"entropy\",     n_estimators=1200, max_depth=10, max_features=\"sqrt\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"entropy\"),\n",
    "    # variantes prior\n",
    "    dict(name=\"alpha_0.2\",   n_estimators=1200, max_depth=10, max_features=\"sqrt\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "    dict(name=\"alpha_0.4\",   n_estimators=1200, max_depth=10, max_features=\"sqrt\", min_samples_leaf=2, class_weight=\"balanced\", criterion=\"gini\"),\n",
    "]\n",
    "# prior_kind=\"rank\" et prior_temp=0.8 fixés ; on bougera alpha juste après\n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    alpha = 0.30\n",
    "    if cfg[\"name\"] == \"alpha_0.2\": alpha = 0.20\n",
    "    if cfg[\"name\"] == \"alpha_0.4\": alpha = 0.40\n",
    "\n",
    "    _, year_table, metrics = run_random_forest_simple(\n",
    "        features, df_champions,\n",
    "        calibrate=False,\n",
    "        blend_prior=True,\n",
    "        prior_kind=\"rank\",\n",
    "        prior_temp=0.8,\n",
    "        alpha=alpha,\n",
    "        n_estimators=cfg[\"n_estimators\"],\n",
    "        max_depth=cfg[\"max_depth\"],\n",
    "        max_features=cfg[\"max_features\"],\n",
    "        min_samples_leaf=cfg[\"min_samples_leaf\"],\n",
    "        class_weight=cfg[\"class_weight\"],\n",
    "        criterion=cfg[\"criterion\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "    rows.append({\n",
    "        \"config\": cfg[\"name\"],\n",
    "        \"top1\": metrics[\"top1\"],\n",
    "        \"top2\": metrics[\"top2\"],\n",
    "        \"brier\": metrics[\"brier\"],\n",
    "        \"logloss\": metrics[\"logloss\"],\n",
    "        \"params\": {k:v for k,v in cfg.items() if k!=\"name\"},\n",
    "        \"alpha\": alpha\n",
    "    })\n",
    "\n",
    "rf_summary = pd.DataFrame(rows).sort_values([\"top1\",\"top2\"], ascending=[False, False]).reset_index(drop=True)\n",
    "rf_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xgboost\"></a>\n",
    "\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_reg import run_xgb_loso_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table_XG, metrics_XG = run_xgb_loso_simple(features, df_champions, target=\"is_champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table_XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    # base (ta config)\n",
    "    dict(name=\"base\", n_estimators=400, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0),\n",
    "\n",
    "    # un peu plus profond\n",
    "    dict(name=\"depth5\", n_estimators=400, max_depth=5, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0),\n",
    "    dict(name=\"depth6\", n_estimators=400, max_depth=6, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0),\n",
    "\n",
    "    # plus d'arbres + LR plus faible\n",
    "    dict(name=\"lr0.04_ne600\", n_estimators=600, max_depth=4, learning_rate=0.04, subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0),\n",
    "    dict(name=\"lr0.03_ne800\", n_estimators=800, max_depth=4, learning_rate=0.03, subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0),\n",
    "\n",
    "    # échantillonnage un poil différent\n",
    "    dict(name=\"sub08_col08\", n_estimators=400, max_depth=4, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0),\n",
    "\n",
    "    # régularisation L2 un peu plus forte\n",
    "    dict(name=\"lambda2\", n_estimators=400, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, reg_lambda=2.0),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "all_year_tables = {}\n",
    "\n",
    "for cfg in configs:\n",
    "    yt, m = run_xgb_loso_simple(\n",
    "        features, df_champions, target=\"is_champion\",\n",
    "        n_estimators=cfg[\"n_estimators\"],\n",
    "        max_depth=cfg[\"max_depth\"],\n",
    "        learning_rate=cfg[\"learning_rate\"],\n",
    "        subsample=cfg[\"subsample\"],\n",
    "        colsample_bytree=cfg[\"colsample_bytree\"],\n",
    "        reg_lambda=cfg[\"reg_lambda\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "    rows.append({\n",
    "        \"config\": cfg[\"name\"],\n",
    "        \"precision_top1\": float(m.loc[0,\"precision_top1\"]),\n",
    "        \"precision_top2\": float(m.loc[0,\"precision_top2\"]),\n",
    "        \"params\": {k:v for k,v in cfg.items() if k!=\"name\"}\n",
    "    })\n",
    "    all_year_tables[cfg[\"name\"]] = yt\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values([\"precision_top1\",\"precision_top2\"], ascending=[False, False]).reset_index(drop=True)\n",
    "print(summary)\n",
    "# Pour voir le détail d'une config donnée (ex. la meilleure) :\n",
    "best_name = summary.loc[0, \"config\"]\n",
    "print(f\"\\n--- Détails meilleure config: {best_name} ---\")\n",
    "all_year_tables[best_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verif_premier(year_table: pd.DataFrame, classement: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare la prédiction du modèle avec l'équipe classée 1ʳᵉ au classement régulier.\n",
    "\n",
    "    Args:\n",
    "        year_table (pd.DataFrame): Résultats par saison (année, predicted, actual, etc.)\n",
    "        classement (pd.DataFrame): Classement complet avec colonnes 'année', 'Club', 'Rang'\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Tableau enrichi avec la colonne 'premier_saison'\n",
    "                      (club classé 1er) et 'same_as_first' (booléen)\n",
    "    \"\"\"\n",
    "    # S'assurer que la colonne s'appelle 'année'\n",
    "    if \"annee\" in year_table.columns:\n",
    "        year_table = year_table.rename(columns={\"annee\": \"année\"})\n",
    "    if \"annee\" in classement.columns:\n",
    "        classement = classement.rename(columns={\"annee\": \"année\"})\n",
    "\n",
    "    # Extraire l'équipe en Rang=1 pour chaque saison\n",
    "    premiers = classement.loc[classement[\"Rang\"] == 1, [\"année\", \"Club\"]].rename(columns={\"Club\": \"premier_saison\"})\n",
    "\n",
    "    # Merge avec le tableau des prédictions\n",
    "    merged = year_table.merge(premiers, on=\"année\", how=\"left\")\n",
    "\n",
    "    # Vérifier si la prédiction correspond au premier\n",
    "    merged[\"same_as_first\"] = (merged[\"predicted\"] == merged[\"premier_saison\"]).astype(int)\n",
    "\n",
    "    return merged[[\"année\", \"predicted\", \"actual\", \"premier_saison\", \"same_as_first\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_premier(year_table_RF, classement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_premier(year_table_XG, classement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predictionElo\"></a>\n",
    "\n",
    "\n",
    "# Prédiction par Elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages:\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "presentation=pd.read_csv('data/presentation.csv')\n",
    "classement=pd.read_csv('data/classement.csv')\n",
    "forme=pd.read_csv('data/forme.csv')\n",
    "evolution=pd.read_csv('data/evolution.csv')\n",
    "resultat=pd.read_csv('data/resultat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_elo import find_best_parameters\n",
    "\n",
    "find_best_parameters(classement, resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test2425\"></a>\n",
    "\n",
    "### TEST sur la saison 24/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_elo import elo_preseason_with_mercato\n",
    "\n",
    "# 2) Tes meilleurs paramètres (SEQUENTIAL updates — deterministic order)\n",
    "H_BEST = 63.837\n",
    "S_BEST = 259.415\n",
    "NU_BEST = 0.031\n",
    "K_BEST = 27.936\n",
    "MARGIN_SCALE_BEST = 2.485\n",
    "\n",
    "W_LAST  = 0.68   # => w_recent\n",
    "W_PREV  = 1 - W_LAST  # = 0.32\n",
    "PROMO_PENALTY_BEST = 0.057\n",
    "BOTTOM_K_BEST = 3\n",
    "\n",
    "# (Optionnel) notes de mercato si tu en as :\n",
    "notes_mercato_2425 = {\n",
    "    \"Stade toulousain\":        6.2,  # stabilité + Naoto Saito, Efrain Elías\n",
    "    \"Union Bordeaux Bègles\":   8.0,  # Carbery, Jonny Gray, Swinton, Retière\n",
    "    \"Stade français Paris\":    5.3,  # Carbonel, Foursans, Tanga, Nicotera\n",
    "    \"Stade rochelais\":         6.8,  # Kane Douglas, Vunivalu (ailier)\n",
    "    \"RC Toulon\":               8.2,  # Sinckler, Ludlam, Frisch, Lucchesi\n",
    "    \"Castres olympique\":       6.8,  # Collier, Ducat, Jedrasiak, Matkava\n",
    "    \"Racing 92\":               8.9,  # Owen Farrell, Bamba, Taofifénua, Dayimani\n",
    "    \"ASM Clermont\":            7.0,  # Ala'alatoa, Tauzin, Hamdaoui\n",
    "    \"Section paloise\":         7.2,  # Klemenczak, Aymeric Luc, Picquette, Kaulashvili\n",
    "    \"USA Perpignan\":           7.1,  # Brookes, Devaux, Aprasidze, Buliruarua, Warion\n",
    "    \"Lyon OU\":                 6.9,  # Ainsley, Lavanini, Matavesi, Gomes Sa (+ Chat)\n",
    "    \"Aviron bayonnais\":        9.5,  # Tuilagi, Segonds, Germain, Alex Moon\n",
    "    \"Montpellier HR\":          6.5,  # Vunipola, Hogg, Uelese, Miotti, Abuladze\n",
    "    \"RC Vannes\":               7.3,  # Mako Vunipola, Nakosi, Tani Vili, Varney, Medrano, Rayasi\n",
    "}\n",
    "\n",
    "# 3) Appel de la fonction\n",
    "elo_with_notes, elo_preseason_df, classement_corrige_2324, table_attendue_2425 = elo_preseason_with_mercato(\n",
    "    classement=classement,\n",
    "    forme=forme,\n",
    "    resultat=resultat,                 # nécessaire pour calculer la table attendue\n",
    "    base_year=2023,                      # 23/24 vient de finir → on prédit 24/25\n",
    "    # --- hyperparams pré-saison (tu peux laisser les défauts) ---\n",
    "    w_last=W_LAST,                       # 75% saison 23/24\n",
    "    w_prev=W_PREV,                       # 25% saison 22/23\n",
    "    rho=0.80,                          # régression vers la moyenne\n",
    "    bottom_k=BOTTOM_K_BEST,\n",
    "    promu=\"RC Vannes\",\n",
    "    relegue=\"US Oyonnax\",\n",
    "    m_equipes=14,\n",
    "    promo_penalty=PROMO_PENALTY_BEST,             # issu de ta recherche\n",
    "    # delta_niveau=-35.0,              # ajuste si tu as estimé un écart de division\n",
    "    # notes_mercato=notes_mercato,     # décommente si tu fournis un dict\n",
    "    # --- shrink par étages (laisse par défaut si tu veux) ---\n",
    "    apply_tier_compress=True,\n",
    "    # --- proba match (Davidson) pour la table attendue ---\n",
    "    H=H_BEST,\n",
    "    s=S_BEST,\n",
    "    nu=NU_BEST,\n",
    "    compute_expected_table=True,\n",
    "    season_for_expected=2024,          # saison 24/25 codée 2024 dans resultat.csv\n",
    "    do_print=False,\n",
    "    #mercato\n",
    "    gamma=6,\n",
    "    notes_mercato=notes_mercato_2425\n",
    ")\n",
    "\n",
    "# (Optionnel) Aperçu rapide\n",
    "print(\"\\nTOP pré-saison (après mercato & shrink):\")\n",
    "print(elo_with_notes.head(5))\n",
    "print(\"\\nClassement attendu 24/25 (points attendus):\")\n",
    "if table_attendue_2425 is not None:\n",
    "    print(table_attendue_2425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_with_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"saison2526\"></a>\n",
    "\n",
    "### Prédiction sur 25/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_mercato_2526 = {\n",
    "    \"USA Perpignan\": 9,\n",
    "    \"Stade rochelais\": 8,\n",
    "    \"Union Bordeaux Bègles\": 8,\n",
    "    \"Lyon OU\": 7.5,\n",
    "    \"Stade toulousain\": 6.5,\n",
    "    \"Aviron bayonnais\": 6.0,\n",
    "    \"RC Toulon\": 5.5,\n",
    "    \"Section paloise\": 5.5,\n",
    "    \"Montpellier HR\": 5.5,\n",
    "    \"Castres olympique\": 5.0,\n",
    "    \"Racing 92\": 5.0,\n",
    "    \"US Montauban\": 4.0,\n",
    "    \"Stade français Paris\": 4.5,\n",
    "    \"ASM Clermont\": 4.5,\n",
    "}\n",
    "\n",
    "elo_2526, elo_pre_2526, cls_corr_2425, table_2526 = elo_preseason_with_mercato(\n",
    "    classement=classement,\n",
    "    forme=forme,\n",
    "    resultat=resultat,\n",
    "    base_year=2024,                      # 24/25 vient de finir → on prédit 25/26\n",
    "    promu=\"US Montauban\",\n",
    "    relegue=\"RC Vannes\",\n",
    "    w_last=W_LAST, w_prev=W_PREV, rho=0.80,\n",
    "    H=H_BEST, s=S_BEST, nu=NU_BEST, bottom_k=BOTTOM_K_BEST,\n",
    "    notes_mercato=notes_mercato_2526,                  \n",
    "    do_print=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_2526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendrier2526 = pd.read_csv(\"data2526/calendrier_2526.csv\")\n",
    "calendrier2526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_elo import print_probas_journee\n",
    "\n",
    "print_probas_journee(elo_2526, calendrier2526, journee=1, H=H_BEST, s=S_BEST, nu=NU_BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_elo import add_scores_for_journee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 matchs pour une journée Top 14\n",
    "scores_J1 = [\"20-16\",\"24-19\",\"18-18\",\"13-27\",\"21-17\",\"26-22\",\"12-09\"] #à modifier\n",
    "\n",
    "calendrier2526_J1 = add_scores_for_journee(calendrier2526, 1, scores_J1, inplace=False)\n",
    "calendrier2526_J1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_elo import update_elo_after_journee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_after_J1 = update_elo_after_journee(elo_2526, calendrier2526_J1, J=1, H=H_BEST, s=S_BEST, nu=NU_BEST, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_after_J1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_probas_journee(elo_after_J1, calendrier2526, journee=2)\n",
    "#scores_J1 = [\"20-16\",\"24-19\",\"18-18\",\"13-27\",\"21-17\",\"26-22\",\"12-09\"] #à modifier\n",
    "#calendrier2526_J2 = add_scores_for_journee(calendrier2526_J1, 2, scores_J2, inplace=False)\n",
    "#elo_after_J2 = update_elo_after_journee(elo_after_J1, calendrier2526_J2, J=2)\n",
    "#elo_after_J2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
